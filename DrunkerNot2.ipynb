{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrunkerNot2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKO9RTgEq8Am"
      },
      "outputs": [],
      "source": [
        "# Second Experiment for DrunkerNot\n",
        "\n",
        "import pathlib\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import os\n",
        "import numpy as np\n",
        "import keras_tuner as kt\n",
        "import matplotlib.pyplot as plt\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "data_dir = os.path.join(PROJECT_ROOT_DIR, \"TrainPhotos\")\n",
        "data_dir2 = os.path.join(PROJECT_ROOT_DIR, \"ValPhotos\")\n",
        "\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir2 = pathlib.Path(data_dir2)\n",
        "print(data_dir)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "\n",
        "# Set Batch size to be all images as we don't care about splitting into batches right now\n",
        "batch_size = image_count\n",
        "img_height = 364\n",
        "img_width = 364\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir2,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "\n",
        "# Get x/y train and x/y test\n",
        "for image_batch, labels_batch in train_ds:\n",
        "    x_train = image_batch.numpy()\n",
        "    y_train = labels_batch.numpy()\n",
        "    break\n",
        "\n",
        "for image_batch, labels_batch in val_ds:\n",
        "    x_test = image_batch.numpy()\n",
        "    y_test = labels_batch.numpy()\n",
        "    break\n",
        "\n",
        "# Divide by 255.0 to reduce the color\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5, 5, i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(x_train[i])\n",
        "#     plt.xlabel(class_names[y_train[i]])\n",
        "# plt.show()\n",
        "\n",
        "# Model Builder for the tuner\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "              input_shape=(364, 364, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                  from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Tuner to find the best hyperparameters\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=data_dir)\n",
        "\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=50,\n",
        "             validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get Best hyperparameters from tuner\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Plot graph of best hyperparamters and the accuracy of each epoch\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0.5, 1])\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.show()\n",
        "\n",
        "# Evaluate model on unseen test data\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "# Print the accuracy on the unseen test data\n",
        "print(\"Accuracy on Test Data: \", test_acc)"
      ]
    }
  ]
}