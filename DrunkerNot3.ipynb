{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrunkerNot3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OR8KdoyrKyD"
      },
      "outputs": [],
      "source": [
        "# Third Experiment for DrunkerNot\n",
        "\n",
        "from keras.preprocessing.image import save_img\n",
        "from functools import partial\n",
        "from types import prepare_class\n",
        "from keras import preprocessing\n",
        "import matplotlib as mpl\n",
        "import sklearn\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import pathlib\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "assert tf.__version__ >= \"2.2\"\n",
        "\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "data_dir = os.path.join(PROJECT_ROOT_DIR, \"TrainPhotos\")\n",
        "data_dir2 = os.path.join(PROJECT_ROOT_DIR, \"ValPhotos\")\n",
        "\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir2 = pathlib.Path(data_dir2)\n",
        "print(data_dir)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "\n",
        "# Set Batch size to be all images as we don't care about splitting into batches right now\n",
        "batch_size = 16\n",
        "# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly\n",
        "img_height = 299\n",
        "img_width = 299\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "\n",
        "# Training Dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# Validation Dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir2,\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = ['DrunkProcessed', 'SoberProcessed']\n",
        "\n",
        "# # Rows and columns are set to fit one training batch (32)\n",
        "# n_rows = 4\n",
        "# n_cols = 2\n",
        "# plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
        "# for images, labels in train_ds.take(1):\n",
        "#     for i in range(n_rows*n_cols):\n",
        "#         plt.subplot(n_rows, n_cols, i + 1)\n",
        "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#         plt.axis('off')\n",
        "#         plt.title(class_names[labels[i]], fontsize=12)\n",
        "# plt.subplots_adjust(wspace=.2, hspace=.2)\n",
        "# plt.show()\n",
        "\n",
        "# base_model = keras.applications.EfficientNetB0(weights=\"imagenet\",\n",
        "#                                                include_top=False)\n",
        "\n",
        "base_model = keras.applications.EfficientNetB7(\n",
        "    weights='imagenet', include_top=False, classes=2)\n",
        "\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(2, activation=\"softmax\")(avg)\n",
        "model = keras.models.Model(inputs=base_model.input,\n",
        "                           outputs=output)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=.2)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=5)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=10)\n",
        "\n",
        "\n",
        "true_y2 = []\n",
        "pred_y2 = []\n",
        "\n",
        "for x, y in val_ds:\n",
        "    prediction = model.predict(x)\n",
        "    pred_labels = np.argmax(prediction, axis=1).tolist()\n",
        "    true_y2 += y.numpy().tolist()\n",
        "    pred_y2 += pred_labels\n",
        "\n",
        "confusion_matrix2 = metrics.confusion_matrix(y_true=true_y2, y_pred=pred_y2)\n",
        "precision = metrics.precision_score(y_true=true_y2, y_pred=pred_y2)\n",
        "f1 = metrics.f1_score(y_true=true_y2, y_pred=pred_y2)\n",
        "recall = metrics.recall_score(y_true=true_y2, y_pred=pred_y2)\n",
        "\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix2, index=[i for i in class_names],\n",
        "                     columns=[i for i in class_names])\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    }
  ]
}